# server_inference.py
import socket
import pickle
import struct
import cv2
import torch
import numpy as np
import torchvision.transforms as transforms
from PIL import Image
import sys
import os
import threading
import queue
import time

# ëª¨ë¸ import
sys.path.append('/home/jhlee/pjt/rootfs/workspace/iccv19_attribute/model')  # ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •
from inception_iccv import inception_iccv

class InferenceServer:
    def __init__(self, model_path, dataset='foottraffic', port=9999, headless=False):
        self.port = port
        self.model_path = model_path
        self.dataset = dataset
        
        # ì†ì„± ì •ë³´ ì„¤ì •
        self.attr_nums = {
            'pa100k': 26, 'rap': 51, 'peta': 35, 'foottraffic': 43
        }
        
        # foottraffic ë°ì´í„°ì…‹ ì†ì„± ì„¤ëª… (ì‹¤ì œ ì†ì„±ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
        self.descriptions = {
            'foottraffic': [
                'male', 'female', 'child', 'teenager', 'adult', 'senior',
                'long_sleeve', 'short_sleeve', 'sleeveless', 'onepice',
                'top_red', 'top_orange', 'top_yellow', 'top_green', 'top_blue',
                'top_purple', 'top_pink', 'top_brown', 'top_white', 'top_grey', 'top_black',
                'long_pants', 'short_pants', 'skirt', 'bottom_type_none',
                'bottom_red', 'bottom_orange', 'bottom_yellow', 'bottom_green', 'bottom_blue',
                'bottom_purple', 'bottom_pink', 'bottom_brown', 'bottom_white', 'bottom_grey', 'bottom_black',
                'carrier', 'umbrella', 'bag', 'hat', 'glasses', 'acc_none', 'pet'
            ],
            'pa100k': [
                'Female', 'AgeOver60', 'Age18-60', 'AgeLess18', 'Front', 'Side', 'Back',
                'Hat', 'Glasses', 'HandBag', 'ShoulderBag', 'Backpack', 'HoldObjectsInFront',
                'ShortSleeve', 'LongSleeve', 'UpperStride', 'UpperLogo', 'UpperPlaid', 'UpperSplice',
                'LowerStripe', 'LowerPattern', 'LongCoat', 'Trousers', 'Shorts', 'Skirt&Dress', 'boots'
            ]
        }
        
        self.num_classes = self.attr_nums[dataset]
        self.attr_descriptions = self.descriptions.get(dataset, [f'attr_{i}' for i in range(self.num_classes)])
        
        # GPU/CPU ì„¤ì •
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self.load_model()
        
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        self.transform = transforms.Compose([
            transforms.Resize((256, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ë©€í‹°ìŠ¤ë ˆë”©ì„ ìœ„í•œ í
        self.frame_queue = queue.Queue(maxsize=5)
        self.result_queue = queue.Queue(maxsize=5)
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.frame_count = 0
        self.inference_times = []

        self.headless = True  # GUI ì‚¬ìš© ì—¬ë¶€
        
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            model = inception_iccv(pretrained=False, num_classes=self.num_classes)
            
            if os.path.exists(self.model_path):
                print(f"ëª¨ë¸ ë¡œë“œ ì‹œì‘: {self.model_path}")
                checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=False)
                
                # ì²´í¬í¬ì¸íŠ¸ì—ì„œ state_dict ì¶”ì¶œ
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                    print(f"ì—í¬í¬: {checkpoint.get('epoch', 'Unknown')}")
                    print(f"ìµœê³  ì •í™•ë„: {checkpoint.get('best_accu', 'Unknown')}")
                else:
                    state_dict = checkpoint
                    
                # DataParallel ëª¨ë“ˆ ì ‘ë‘ì‚¬ ì œê±°
                new_state_dict = {}
                for k, v in state_dict.items():
                    if k.startswith('module.'):
                        new_state_dict[k[7:]] = v
                    else:
                        new_state_dict[k] = v
                        
                model.load_state_dict(new_state_dict)
                print("âœ“ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                print("Pretrained ImageNet weightsë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
            model.to(self.device)
            model.eval()
            print(f"âœ“ ëª¨ë¸ì´ {self.device}ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return model
            
        except Exception as e:
            print(f"âœ— ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def preprocess_image(self, cv_image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # BGR to RGB
            rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_image)
            
            # ì „ì²˜ë¦¬ ì ìš©
            tensor_image = self.transform(pil_image).unsqueeze(0)
            return tensor_image.to(self.device)
        except Exception as e:
            print(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def predict(self, image_tensor):
        """ì†ì„± ì˜ˆì¸¡"""
        try:
            start_time = time.time()
            
            with torch.no_grad():
                output = self.model(image_tensor)
                
                # ë‹¤ì¤‘ ì¶œë ¥ ì²˜ë¦¬
                if isinstance(output, (tuple, list)):
                    final_output = output[0]
                    for i in range(1, len(output)):
                        final_output = torch.max(final_output, output[i])
                else:
                    final_output = output
                    
                # í™•ë¥  ê³„ì‚°
                probabilities = torch.sigmoid(final_output).cpu().numpy()[0]
                predictions = (probabilities > 0.5).astype(int)
                
                inference_time = time.time() - start_time
                self.inference_times.append(inference_time)
                
                return predictions, probabilities, inference_time
                
        except Exception as e:
            print(f"ì¶”ë¡  ì˜¤ë¥˜: {e}")
            return None, None, 0
    
    def inference_worker(self):
        """ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        print("ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
        
        while True:
            try:
                item = self.frame_queue.get(timeout=1)
                if item is None:  # ì¢…ë£Œ ì‹ í˜¸
                    break
                    
                frame, timestamp = item
                
                # ì „ì²˜ë¦¬
                image_tensor = self.preprocess_image(frame)
                if image_tensor is None:
                    continue
                    
                # ì¶”ë¡ 
                predictions, probabilities, inference_time = self.predict(image_tensor)
                if predictions is not None:
                    self.result_queue.put((frame, predictions, probabilities, timestamp, inference_time))
                
                self.frame_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"ì›Œì»¤ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
    
    def draw_predictions(self, image, predictions, probabilities, inference_time, confidence_threshold=0.6):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°"""
        h, w = image.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = image.copy()
        cv2.rectangle(overlay, (10, 10), (w-10, min(h-10, 400)), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)
        
        # ì œëª©
        cv2.putText(image, "Pedestrian Attributes (Server)", (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # ì„±ëŠ¥ ì •ë³´
        avg_inference_time = np.mean(self.inference_times[-30:]) if self.inference_times else 0
        cv2.putText(image, f"Inference: {inference_time*1000:.1f}ms (avg: {avg_inference_time*1000:.1f}ms)", 
                   (20, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        
        cv2.putText(image, f"Device: {self.device.upper()}", (20, 85), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        
        # ì†ì„± ì˜ˆì¸¡ ê²°ê³¼
        y_offset = 110
        line_height = 18
        
        # ë†’ì€ ì‹ ë¢°ë„ì˜ ì†ì„±ë§Œ ì„ íƒ
        positive_attrs = []
        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            if pred == 1 and prob > confidence_threshold:
                attr_name = self.attr_descriptions[i]
                positive_attrs.append((attr_name, prob))
        
        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        positive_attrs.sort(key=lambda x: x[1], reverse=True)
        
        # ìƒìœ„ ì†ì„±ë“¤ í‘œì‹œ (ìµœëŒ€ 12ê°œ)
        max_attrs = min(12, len(positive_attrs))
        if max_attrs == 0:
            cv2.putText(image, "No significant attributes detected", (20, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)
        else:
            for i, (attr_name, prob) in enumerate(positive_attrs[:max_attrs]):
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€ê²½
                if prob > 0.8:
                    color = (0, 255, 0)  # ì´ˆë¡ (ë†’ì€ ì‹ ë¢°ë„)
                elif prob > 0.7:
                    color = (0, 255, 255)  # ë…¸ë‘ (ì¤‘ê°„ ì‹ ë¢°ë„)
                else:
                    color = (0, 165, 255)  # ì£¼í™© (ë‚®ì€ ì‹ ë¢°ë„)
                
                text = f"{attr_name}: {prob:.3f}"
                cv2.putText(image, text, (20, y_offset + i * line_height), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        return image
    
    def start_server(self):
        """ì„œë²„ ì‹œì‘"""
        print(f"=== Pedestrian Attribute Inference Server ===")
        print(f"í¬íŠ¸: {self.port}")
        print(f"ë°ì´í„°ì…‹: {self.dataset} ({self.num_classes} attributes)")
        print(f"ëª¨ë¸: {self.model_path}")
        print()
        
        # ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        inference_thread = threading.Thread(target=self.inference_worker)
        inference_thread.daemon = True
        inference_thread.start()
        
        # ì†Œì¼“ ì„œë²„ ì„¤ì •
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        
        try:
            sock.bind(('localhost', self.port))  # localhostë¡œ ë°”ì¸ë”©
            sock.listen(1)
            print(f"ì„œë²„ ëŒ€ê¸° ì¤‘... í¬íŠ¸ {self.port}")
            print("í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŒ€ê¸°ì¤‘...")
            print("SSH í¬íŠ¸ í¬ì›Œë”©: ssh -L 9999:localhost:9999 username@server_ip")
            print()
            
            conn, addr = sock.accept()
            print(f"âœ“ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {addr}")
            
            data = b""
            payload_size = struct.calcsize("Q")
            
            start_time = time.time()
            received_frames = 0
            
            while True:
                try:
                    # í”„ë ˆì„ í¬ê¸° ìˆ˜ì‹ 
                    while len(data) < payload_size:
                        packet = conn.recv(4*1024)
                        if not packet:
                            print("í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
                            return
                        data += packet
                    
                    packed_msg_size = data[:payload_size]
                    data = data[payload_size:]
                    msg_size = struct.unpack("Q", packed_msg_size)[0]
                    
                    # í”„ë ˆì„ ë°ì´í„° ìˆ˜ì‹ 
                    while len(data) < msg_size:
                        packet = conn.recv(4*1024)
                        if not packet:
                            print("í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
                            return
                        data += packet
                    
                    frame_data = data[:msg_size]
                    data = data[msg_size:]
                    
                    # í”„ë ˆì„ ë””ì½”ë”©
                    frame_buffer = pickle.loads(frame_data)
                    frame = cv2.imdecode(frame_buffer, cv2.IMREAD_COLOR)
                    
                    if frame is not None:
                        received_frames += 1
                        timestamp = time.time()
                        
                        # ì¶”ë¡  íì— ì¶”ê°€ (íê°€ ê°€ë“ ì°¨ë©´ ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±°)
                        if self.frame_queue.full():
                            try:
                                self.frame_queue.get_nowait()
                            except queue.Empty:
                                pass
                        
                        self.frame_queue.put((frame, timestamp))
                        
                        # ê²°ê³¼ í‘œì‹œ
                        display_frame = frame.copy()

                        # try:
                        #     result_frame, predictions, probabilities, result_timestamp, inference_time = self.result_queue.get_nowait()
                        #     display_frame = self.draw_predictions(result_frame, predictions, probabilities, inference_time)
                        # except queue.Empty:
                        #     # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë³¸ í”„ë ˆì„ì— ëŒ€ê¸° ë©”ì‹œì§€ í‘œì‹œ
                        #     cv2.putText(display_frame, "Processing...", (20, 50), 
                        #                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

                            # ìˆ˜ì •ëœ ì½”ë“œ:
                        try:
                            result_frame, predictions, probabilities, result_timestamp, inference_time = self.result_queue.get_nowait()
                            
                            # ì¶”ë¡  ê²°ê³¼ë¥¼ ì½˜ì†”ì— ìì„¸íˆ ì¶œë ¥
                            self.print_detailed_predictions(predictions, probabilities, inference_time, received_frames)
                            
                            # GUIê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ í™”ë©´ í‘œì‹œ
                            if not self.headless:
                                display_frame = self.draw_predictions(result_frame, predictions, probabilities, inference_time)
                                cv2.imshow("Server Inference Result", display_frame)
                                if cv2.waitKey(1) == ord('q'):
                                    print("ì„œë²„ ì¢…ë£Œ ìš”ì²­")
                                    break
                                    
                        except queue.Empty:
                            # 30í”„ë ˆì„ë§ˆë‹¤ ìƒíƒœ ì¶œë ¥
                            if received_frames % 30 == 0:
                                print(f"[INFO] í”„ë ˆì„ {received_frames} ìˆ˜ì‹  ì™„ë£Œ - ì¶”ë¡  ëŒ€ê¸° ì¤‘...")


                        # FPS ê³„ì‚°
                        if received_frames % 30 == 0:
                            elapsed = time.time() - start_time
                            fps = received_frames / elapsed
                            print(f"ìˆ˜ì‹  FPS: {fps:.1f}, ì´ í”„ë ˆì„: {received_frames}")
                        
                        # í™”ë©´ì— í‘œì‹œ
                        # cv2.imshow("Server Inference Result", display_frame)
            # GUI ì‚¬ìš© ì—¬ë¶€ ì œì–´
                        if not self.headless:
                            cv2.imshow("Server Inference Result", display_frame)
                            if cv2.waitKey(1) == ord('q'):
                                print("ì„œë²„ ì¢…ë£Œ ìš”ì²­")
                                break
                        else:
                            # ì½˜ì†”ì— ê²°ê³¼ ì¶œë ¥
                            if received_frames % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ ì¶œë ¥
                                print(f"í”„ë ˆì„ {received_frames} ì²˜ë¦¬ ì™„ë£Œ")
                                # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶œë ¥
                                try:
                                    result_frame, predictions, probabilities, result_timestamp, inference_time = self.result_queue.get_nowait()
                                    positive_attrs = []
                                    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
                                        if pred == 1 and prob > 0.6:
                                            attr_name = self.attr_descriptions[i]
                                            positive_attrs.append((attr_name, prob))
                                    
                                    positive_attrs.sort(key=lambda x: x[1], reverse=True)
                                    print(f"ê°ì§€ëœ ì†ì„±: {', '.join([f'{name}({prob:.2f})' for name, prob in positive_attrs[:5]])}")
                                except:
                                    pass
                        
                        if cv2.waitKey(1) == ord('q'):
                            print("ì„œë²„ ì¢…ë£Œ ìš”ì²­")
                            break
                            
                except Exception as e:
                    print(f"í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"ì„œë²„ ì˜¤ë¥˜: {e}")
        finally:
            # ì •ë¦¬
            self.frame_queue.put(None)  # ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
            try:
                conn.close()
            except:
                pass
            sock.close()
            cv2.destroyAllWindows()
            print("ì„œë²„ ì¢…ë£Œ")

    def print_detailed_predictions(self, predictions, probabilities, inference_time, frame_num, confidence_threshold=0.5):
        """ìƒì„¸í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥"""

        # ëª¨ë“  ì˜ˆì¸¡ëœ ì†ì„± ìˆ˜ì§‘
        all_predictions = []
        positive_predictions = []

        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            attr_name = self.attr_descriptions[i]
            all_predictions.append((attr_name, pred, prob))

            if pred == 1 and prob > confidence_threshold:
                positive_predictions.append((attr_name, prob))

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*80}")
        print(f"í”„ë ˆì„ {frame_num} | ì¶”ë¡  ì‹œê°„: {inference_time*1000:.1f}ms")
        print(f"{'='*80}")

        if positive_predictions:
            # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            positive_predictions.sort(key=lambda x: x[1], reverse=True)

            print("ğŸ” ê°ì§€ëœ ì†ì„±:")
            for i, (attr_name, prob) in enumerate(positive_predictions, 1):
                confidence_level = "ğŸŸ¢" if prob > 0.8 else "ğŸŸ¡" if prob > 0.6 else "ğŸŸ "
                print(f"  {i:2d}. {confidence_level} {attr_name:<20} : {prob:.3f}")
        else:
            print("âŒ ì‹ ë¢°ë„ê°€ ë†’ì€ ì†ì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ìƒìœ„ 5ê°œ í™•ë¥  í‘œì‹œ (ì˜ˆì¸¡ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
        print(f"\nğŸ“Š ìƒìœ„ 5ê°œ í™•ë¥ :")
        top_probs = sorted(all_predictions, key=lambda x: x[2], reverse=True)[:5]
        for i, (attr_name, pred, prob) in enumerate(top_probs, 1):
            status = "âœ…" if pred == 1 else "âŒ"
            print(f"  {i}. {status} {attr_name:<20} : {prob:.3f}")

        print(f"{'='*80}\n")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Pedestrian Attribute Inference Server')
    parser.add_argument('--model_path', type=str, required=True, 
                       help='Path to the trained model checkpoint')
    parser.add_argument('--dataset', type=str, default='foottraffic', 
                       choices=['foottraffic', 'pa100k', 'rap', 'peta'],
                       help='Dataset type (default: foottraffic)')
    parser.add_argument('--port', type=int, default=9999, 
                       help='Server port (default: 9999)')
    parser.add_argument('--headless', action='store_true',
                       help='Run without GUI (recommended for SSH)')
    
    args = parser.parse_args()
    
    # ì„œë²„ ì‹œì‘
    server = InferenceServer(args.model_path, args.dataset, args.port)
    server.start_server()
